services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.6.0
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
    ports:
      - "2181:2181"

  kafka:
    image: confluentinc/cp-kafka:7.6.0
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1

  airflow:
    image: apache/airflow:2.9.2
    env_file: 
      - ../config/.env
    environment:
      NO_PROXY: 169.254.169.254,169.254.0.0/16,localhost,127.0.0.1
      no_proxy: 169.254.169.254,169.254.0.0/16,localhost,127.0.0.1
      AIRFLOW__CORE__LOAD_EXAMPLES: "False"
      AIRFLOW__WEBSERVER__RBAC: "True"
      AWS_REGION: "eu-central-1"
      AWS_PROFILE: "default"
      AWS_SDK_LOAD_CONFIG: "1"
    depends_on:
      - kafka
    ports:
      - "8080:8080"
    volumes:
      - ../airflow/dags:/opt/airflow/dags
      - ../docker/airflow/requirements.txt:/requirements.txt
      - airflow-home:/opt/airflow           # <-- persist Airflow home (SQLite lives here)
      - ~/.aws:/home/airflow/.aws:ro   # mount your local AWS config/creds
      - $HOME/.aws:/home/airflow/.aws:ro
    command: >
      bash -lc "
      python -V &&
      python -m pip install --no-cache-dir -r /requirements.txt &&
      airflow standalone
      "
    build: ./airflow

  kafka-producer:
    build: ../kafka/producer
    env_file: ../config/.env
    depends_on:
      - kafka
    command: python produce_events.py

volumes:
  airflow-home:
